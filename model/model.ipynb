{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a46db8-a239-4b61-b410-0ea7694620ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import cross_val_score,train_test_split,cross_val_predict,KFold,cross_validate\n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier\n",
    "    from bayes_opt import BayesianOptimization\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import lightgbm as lgb\n",
    "    import xgboost as xgb\n",
    "    from sklearn.manifold import TSNE \n",
    "    import time\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import AllChem, QED,Draw,MACCSkeys,Descriptors,ChemicalFeatures,DataStructs\n",
    "    from rdkit.Chem.Draw import rdMolDraw2D\n",
    "    from rdkit.Chem.Draw import IPythonConsole\n",
    "    from rdkit import rdBase,DataStructs\n",
    "    from matplotlib.ticker import AutoMinorLocator,MultipleLocator,FormatStrFormatter,LinearLocator,NullLocator,FixedLocator,IndexLocator,AutoLocator\n",
    "    import matplotlib as mpl\n",
    "    from IPython.display import SVG\n",
    "    from rdkit.ML.Cluster import Butina\n",
    "    from rdkit.Chem.Draw.MolDrawing import MolDrawing, DrawingOptions \n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c5b0e2-77a3-47ad-9960-959e7c85515c",
   "metadata": {},
   "source": [
    "# Data Processin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ed2522-30ad-405f-841a-0ffa6e8e053c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path,size=0.2,random_state=np.random.randint(100000000)):\n",
    "    df = pd.read_csv(path)\n",
    "    x,y = df.iloc[:,:-1],df.iloc[:,-1]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=size,random_state=random_state)\n",
    "    return df,x_train, x_test, y_train, y_test,random_state\n",
    "df,x_train, x_test, y_train, y_test,random_state = read_csv('../data/Fingerprint/ripk1_finger.csv',random_state=23)\n",
    "\n",
    "def data_drop(random_state=23,frac=1):\n",
    "    df_label = df.copy()\n",
    "    df_label['label'] = df_label['label'].sample(frac=frac,random_state=random_state).reset_index(drop=True)\n",
    "    return df_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41e162c-3538-499a-9833-9acec3baca0c",
   "metadata": {},
   "source": [
    "# Bayesian optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d756cc5-4ec0-4149-894f-9f563a3903be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lightgbm tune\n",
    "def bayes_objective(eta,max_depth,feature_fraction,num_leaves,lambda_l1,lambda_l2,subsample):\n",
    "    train = lgb.Dataset(x_train, y_train)\n",
    "    valid = lgb.Dataset(x_test,y_test)\n",
    "    params = {'eta': eta,'objective': 'binary', 'metric': 'auc',\n",
    "    'boosting':'gbdt','lambda_l2': lambda_l2,'max_depth':int(max_depth),\n",
    "    'feature_fraction':feature_fraction,'lambda_l1':lambda_l1,\n",
    "    'num_leaves':int(num_leaves),'subsample':subsample,'verbosity':-1} \n",
    "    gbm = lgb.train(params, train, num_boost_round=1000, \n",
    "           valid_sets=[train,valid],valid_names = ['dtrain','dtest'],early_stopping_rounds=50, verbose_eval=40,\n",
    "           callbacks=[lgb.early_stopping(50),lgb.record_evaluation({})],feature_name=list(x_train.columns))\n",
    "    y_pred = gbm.predict(x_test)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    return auc\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    params = {\"eta\": (0.00005, 1),\"num_leaves\": (2,100), \"feature_fraction\": (0.001, 1.0),\n",
    "        'max_depth':(1,10),'lambda_l1':(0,10),'subsample':(0.001,1.0),'lambda_l2':(0,10)}\n",
    "    opt = BayesianOptimization(bayes_objective,params)\n",
    "    opt.maximize(20,20)\n",
    "    print('\\n','\\n','best params:',opt.max['params'],'\\n','\\n','best score:',opt.max['target'],'\\t','It takes %s minutes '% ((time.time()-start)/60))\n",
    "    lgb_params = opt.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645752f-5bab-4a23-b49f-0e19cbb0a50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost tune\n",
    "def bayes_objective(eta,max_depth,lambda_,alpha,subsample,min_child_weight,gamma,colsample_bytree):\n",
    "    train = xgb.DMatrix(x_train, y_train)\n",
    "    valid = xgb.DMatrix(x_test,y_test)\n",
    "    params = {'eta': eta,'objective': 'binary:logistic', 'eval_metric': 'auc',\n",
    "    'booster':'gbtree','lambda': lambda_,'max_depth':int(max_depth),'gamma':gamma,\n",
    "    'colsample_bytree': colsample_bytree,'min_child_weight':min_child_weight,\n",
    "    'alpha':alpha,'subsample':subsample,'verbosity':0} \n",
    "    xgb_model = xgb.train(params,dtrain = train, num_boost_round=1000,\n",
    "                                evals=[(train,'dtrain'),(valid, 'eval')] ,\n",
    "                                early_stopping_rounds=50, verbose_eval=40)\n",
    "    y_pred = xgb_model.predict(valid)\n",
    "    auc = metrics.roc_auc_score(y_test, y_pred)\n",
    "    return auc\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    params = {\"eta\": (0.00005, 1),\"min_child_weight\": (1,5), \"colsample_bytree\": (0.001, 1.0),\n",
    "        'max_depth':(1,10),'lambda_':(0,10),'subsample':(0.001,1.0),'alpha':(0,10),'gamma':(0,10)}\n",
    "    opt = BayesianOptimization(bayes_objective,params)\n",
    "    opt.maximize(20,20)\n",
    "    print('\\n','\\n','best params:',opt.max['params'],'\\n','\\n','best score:',opt.max['target'],'It takes %s minutes '% ((time.time()-start)/60))\n",
    "    xgb_params = opt.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4b7916-db41-4c17-8661-414ef9e0f053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf tune\n",
    "def bayes_objective(max_depth,min_samples_split,min_samples_leaf,max_features,max_samples,n_estimators):\n",
    "    params = {'criterion': 'gini','n_estimators':int(n_estimators),'max_depth':int(max_depth),\n",
    "    'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf,\n",
    "    'max_features':max_features,'max_samples':max_samples} \n",
    "    rfc = RandomForestClassifier(**params)\n",
    "    rfc_model = rfc.fit(x_train,y_train)\n",
    "    y_pred = rfc_model.predict_proba(x_test)\n",
    "    auc = metrics.roc_auc_score(y_test,y_pred[:,1])\n",
    "    return auc\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    params = {\"min_samples_split\": (0.001, 0.9999),\"min_samples_leaf\": (0.001,0.5), \"max_features\": (0.001,0.9999),\n",
    "        'max_depth':(1,20),'max_samples':(0.001,0.9999),'n_estimators':(50,500)}\n",
    "    opt = BayesianOptimization(bayes_objective,params)\n",
    "    opt.maximize(50,50)\n",
    "    print('\\n','\\n','best params:',opt.max['params'],'\\n','\\n','best score:',opt.max['target'],'It takes %s minutes '% ((time.time()-start)/60))\n",
    "    rf_params = opt.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db56913b-556f-4fd9-9caf-444209f81245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# et tune\n",
    "def bayes_objective(max_depth,min_samples_split,min_samples_leaf,max_features,max_samples,n_estimators):\n",
    "    params = {'criterion': 'gini','n_estimators':int(n_estimators),'max_depth':int(max_depth),\n",
    "    'min_samples_split':min_samples_split,'min_samples_leaf':min_samples_leaf,\n",
    "    'max_features':max_features,'max_samples':max_samples} \n",
    "    et = ExtraTreesClassifier(**params)\n",
    "    et_model = et.fit(x_train,y_train)\n",
    "    y_pred = et_model.predict_proba(x_test)\n",
    "    auc = metrics.roc_auc_score(y_test,y_pred[:,1])\n",
    "    return auc\n",
    "if __name__ == '__main__':\n",
    "    start = time.time()\n",
    "    params = {\"min_samples_split\": (0.001, 0.9999),\"min_samples_leaf\": (0.001,0.5), \"max_features\": (0.001,0.9999),\n",
    "        'max_depth':(1,20),'max_samples':(0.001,0.9999),'n_estimators':(50,500)}\n",
    "    opt = BayesianOptimization(bayes_objective,params)\n",
    "    opt.maximize(50,50)\n",
    "    print('\\n','\\n','best params:',opt.max['params'],'\\n','\\n','best score:',opt.max['target'],'It takes %s minutes '% ((time.time()-start)/60))\n",
    "    et_params = opt.max['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c194e8-5de7-444c-b726-9f7b3564bd36",
   "metadata": {},
   "source": [
    "# The best combination of hyperparameters obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865eaa3d-bdb7-4cd5-a126-490abf943071",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {'eta': 0.1,'objective': 'binary','metric':'auc','max_depth':9,\n",
    "              'feature_fraction':0.7267,'lambda_l1':1,'num_leaves':34,'verbosity':-1}\n",
    "xgb_params = {'colsample_bytree': 0.8, 'eta': 0.1, 'gamma': 0.1, 'lambda': 1,'max_depth': 6,\n",
    "              'min_child_weight': 1.0, 'subsample': 0.8,'objective':'binary:logistic','eval_metric': 'auc','verbosity':0}\n",
    "rf_params = {'max_depth': 10.0, 'max_features': 0.1, 'min_samples_split': 27, 'n_estimators': 72}\n",
    "et_params = {'max_depth': 19, 'max_features': 0.09966, 'min_samples_split': 59, 'n_estimators': 104} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99094d4-8b53-4451-bcc3-5dece857592b",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b66277f-668c-4986-b0a3-1c9123321725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(model_type,x_train,y_train,x_test,y_test,random_state=None,**kwargs):\n",
    "    assert type(model_type)==str,print('string type required')\n",
    "    if model_type=='lb':\n",
    "        train = lgb.Dataset(x_train,y_train)\n",
    "        valid = lgb.Dataset(x_test,y_test)\n",
    "        lgb_model = lgb.train(kwargs, train_set = train, num_boost_round = 1000, valid_sets=[train,valid],\n",
    "                                valid_names =['dtrain','dtest'], verbose_eval=30,callbacks=[ \n",
    "                                lgb.early_stopping(50),lgb.record_evaluation({})],\n",
    "                                feature_name=x_train.columns.to_list())\n",
    "        y_pred = lgb_model.predict(x_test, num_iteration=lgb_model.best_iteration)\n",
    "        y_train_pred = lgb_model.predict(x_train, num_iteration=lgb_model.best_iteration)\n",
    "        return lgb_model,y_pred,y_train_pred\n",
    "    \n",
    "    elif model_type=='xb':\n",
    "        train = xgb.DMatrix(x_train, y_train)\n",
    "        valid = xgb.DMatrix(x_test, y_test)   \n",
    "        xgb_model = xgb.train(kwargs,dtrain = train, num_boost_round=1000,\n",
    "                                evals=[(train,'dtrain'),(valid, 'eval')] ,\n",
    "                                early_stopping_rounds=50, verbose_eval=30)\n",
    "        y_pred = xgb_model.predict(valid, iteration_range=(0, xgb_model.best_iteration+1))\n",
    "        y_train_pred = xgb_model.predict(train, iteration_range=(0, xgb_model.best_iteration+1))\n",
    "        return xgb_model,y_pred,y_train_pred\n",
    "        \n",
    "    elif model_type=='rf':\n",
    "        rfc = RandomForestClassifier(random_state=random_state,**kwargs) # class_weight={0:1,1:1}\n",
    "        rf_model = rfc.fit(x_train,y_train)\n",
    "        y_pred = rf_model.predict_proba(x_test)\n",
    "        y_train_pred = rf_model.predict_proba(x_train)\n",
    "        print('ok')\n",
    "        return rf_model,y_pred,y_train_pred\n",
    "    \n",
    "    else :\n",
    "        et = ExtraTreesClassifier(random_state=random_state,**kwargs)\n",
    "        et_model = et.fit(x_train,y_train)\n",
    "        y_pred = et_model.predict_proba(x_test)\n",
    "        y_train_pred = et_model.predict_proba(x_train)\n",
    "        print('ok')\n",
    "        return et_model,y_pred,y_train_pred\n",
    "\n",
    "\n",
    "def model_predict(model:str,ytrue, ypred):\n",
    "    if model == 'lb' or model == 'xb':\n",
    "        pred = [1 if y >= 0.5 else 0 for y in ypred]\n",
    "        auc = metrics.roc_auc_score(y_test, ypred)\n",
    "        acc = metrics.accuracy_score(y_test,pred)\n",
    "        precesion = metrics.precision_score(y_test,pred)\n",
    "        recall = metrics.recall_score(y_test,pred)\n",
    "        f1 = metrics.f1_score(y_test, pred)\n",
    "        mcc = metrics.matthews_corrcoef(y_test, pred)\n",
    "        cm = metrics.confusion_matrix(y_test, pred,labels=[0,1]).astype(np.int32)\n",
    "        sp = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    \n",
    "    if model == 'rf' or model == 'et':\n",
    "        pred = [1 if y >= 0.5 else 0 for y in ypred[:,1]]\n",
    "        auc = metrics.roc_auc_score(y_test, ypred[:,1])\n",
    "        acc = metrics.accuracy_score(y_test,pred)\n",
    "        precesion = metrics.precision_score(y_test,pred)\n",
    "        recall = metrics.recall_score(y_test,pred)\n",
    "        f1 = metrics.f1_score(y_test, pred)\n",
    "        mcc = metrics.matthews_corrcoef(y_test, pred)\n",
    "        cm = metrics.confusion_matrix(y_test, pred,labels=[0,1]).astype(np.int32)\n",
    "        sp = cm[0][0]/(cm[0][0]+cm[0][1])\n",
    "    \n",
    "    return auc,acc,precesion,recall,f1,mcc,cm,sp\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    lgb_model,lb_y_pred ,lb_y_train_pred= model('lb',x_train,y_train,x_test,y_test,**lgb_params)\n",
    "    xgb_model,xb_y_pred ,xb_y_train_pred= model('xb',x_train,y_train,x_test,y_test,**xgb_params)\n",
    "    rf_model,rf_y_pred ,rf_y_train_pred= model('rf',x_train,y_train,x_test,y_test,random_state=123123,**rf_params)\n",
    "    et_model,et_y_pred ,et_y_train_pred= model('et',x_train,y_train,x_test,y_test,random_state=100,**et_params)\n",
    "    lb_auc,lb_acc,lb_precesion,lb_recall,lb_f1,lb_mcc,lb_cm,lb_sp = model_predict('lb',y_test,lb_y_pred)\n",
    "    xb_auc,xb_acc,xb_precesion,xb_recall,xb_f1,xb_mcc,xb_cm,xb_sp = model_predict('xb',y_test,xb_y_pred)\n",
    "    rf_auc,rf_acc,rf_precesion,rf_recall,rf_f1,rf_mcc,rf_cm,rf_sp = model_predict('rf',y_test,rf_y_pred)\n",
    "    et_auc,et_acc,et_precesion,et_recall,et_f1,et_mcc,et_cm,et_sp = model_predict('et',y_test,et_y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bfbec3f-d51a-4914-9d5f-4f3a89e3100e",
   "metadata": {},
   "source": [
    "# Ten-fold cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2711151e-abf6-45e3-aba6-6724332517c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_valid(model_type,n_splits=10,shuffle=True,random_state=23,**kwargs):\n",
    "    auc,acc,precesion,recall,f1,cm,mcc,sp = [],[],[],[],[],[],[],[]\n",
    "    kfold = KFold(n_splits=n_splits,shuffle=shuffle,random_state=random_state)\n",
    "    print(kwargs)\n",
    "    if model_type == 'lb':\n",
    "        for i,j in enumerate(kfold.split(x_train, y_train),1):\n",
    "            train_index, test_index = j\n",
    "            this_train_x,this_train_y = x_train.iloc[train_index,:],y_train.values[train_index]   \n",
    "            this_test_x,this_test_y = x_train.iloc[test_index,:],y_train.values[test_index]  \n",
    "            train = lgb.Dataset(this_train_x, this_train_y)\n",
    "            valid = lgb.Dataset(this_test_x,this_test_y)\n",
    "            lgb_model = lgb.train(kwargs, \n",
    "                       train_set = train, \n",
    "                       num_boost_round=1000, \n",
    "                       valid_sets = [train,valid],\n",
    "                       valid_names = ['dtrain','dtest'],\n",
    "                       callbacks = [lgb.early_stopping(50),lgb.record_evaluation({})],\n",
    "                       verbose_eval = 40,feature_name = list(x_train.columns))\n",
    "            y_pred = lgb_model.predict(this_test_x, iteration_range=(0, lgb_model.best_iteration+1))\n",
    "            pred = [1 if y >= 0.5 else 0 for y in y_pred]\n",
    "            auc.append(metrics.roc_auc_score(this_test_y, y_pred))\n",
    "            acc.append(metrics.accuracy_score(this_test_y,pred))\n",
    "            precesion.append(metrics.precision_score(this_test_y,pred))\n",
    "            recall.append(metrics.recall_score(this_test_y,pred))\n",
    "            f1.append(metrics.f1_score(this_test_y, pred))\n",
    "            cm.append(metrics.confusion_matrix(this_test_y, pred,labels=[0,1]))\n",
    "            mcc.append(metrics.matthews_corrcoef(this_test_y, pred))\n",
    "            print('*'*30,i,'*'*30)\n",
    "        sp.extend([cm[i-1][0][0]/(cm[i-1][0][0]+cm[i-1][0][1]) for i in range(kfold.n_splits)])\n",
    "    \n",
    "    elif model_type == 'xb':\n",
    "        for i,j in enumerate(kfold.split(x_train, y_train),1):\n",
    "            train_index, test_index = j\n",
    "            this_train_x,this_train_y = x_train.iloc[train_index,:],y_train.values[train_index]   \n",
    "            this_test_x,this_test_y = x_train.iloc[test_index,:],y_train.values[test_index] \n",
    "            train = xgb.DMatrix(this_train_x, this_train_y)\n",
    "            valid = xgb.DMatrix(this_test_x,this_test_y)\n",
    "            xgb_model = xgb.train(kwargs, train, num_boost_round=1000,\n",
    "                             evals=[(train,'dtrain'),(valid, 'eval')], \n",
    "                             early_stopping_rounds=50, verbose_eval=40)   \n",
    "            y_pred = xgb_model.predict(valid, iteration_range=(0, xgb_model.best_iteration+1))\n",
    "            pred = [1 if y >= 0.5 else 0 for y in y_pred]\n",
    "            auc.append(metrics.roc_auc_score(this_test_y, y_pred))\n",
    "            acc.append(metrics.accuracy_score(this_test_y,pred))\n",
    "            precesion.append(metrics.precision_score(this_test_y,pred))\n",
    "            recall.append(metrics.recall_score(this_test_y,pred))\n",
    "            f1.append(metrics.f1_score(this_test_y, pred))\n",
    "            cm.append(metrics.confusion_matrix(this_test_y, pred,labels=[0,1]))\n",
    "            mcc.append(metrics.matthews_corrcoef(this_test_y, pred))\n",
    "            print('*'*30,i,'*'*30)\n",
    "        sp.extend([cm[i-1][0][0]/(cm[i-1][0][0]+cm[i-1][0][1]) for i in range(kfold.n_splits)])\n",
    "        \n",
    "    else :\n",
    "        for i,j in enumerate(kfold.split(x_train, y_train),1):\n",
    "            train_index, test_index = j\n",
    "            this_train_x,this_train_y = x_train.iloc[train_index,:],y_train.values[train_index]\n",
    "            this_test_x,this_test_y = x_train.iloc[test_index,:], y_train.values[test_index]  \n",
    "            if model_type == 'rf':\n",
    "                rfc = RandomForestClassifier(**kwargs)\n",
    "                rfc_model = rfc.fit(this_train_x,this_train_y)\n",
    "                y_pred = rfc_model.predict_proba(this_test_x)\n",
    "            elif model_type == 'et':\n",
    "                et = ExtraTreesClassifier(**kwargs)\n",
    "                et_model = et.fit(this_train_x,this_train_y)\n",
    "                y_pred = et_model.predict_proba(this_test_x)\n",
    "            pred = [1 if y >= 0.5 else 0 for y in y_pred[:,1]]\n",
    "            auc.append(metrics.roc_auc_score(this_test_y, y_pred[:,1]))\n",
    "            acc.append(metrics.accuracy_score(this_test_y,pred))\n",
    "            precesion.append(metrics.precision_score(this_test_y,pred))\n",
    "            recall.append(metrics.recall_score(this_test_y,pred))\n",
    "            f1.append(metrics.f1_score(this_test_y, pred))\n",
    "            cm.append(metrics.confusion_matrix(this_test_y, pred,labels=[0,1]))\n",
    "            mcc.append(metrics.matthews_corrcoef(this_test_y, pred))\n",
    "            print('*'*30,i,'*'*30)\n",
    "        sp.extend([cm[i-1][0][0]/(cm[i-1][0][0]+cm[i-1][0][1]) for i in range(kfold.n_splits)])\n",
    "    return auc,acc,precesion,recall,f1,cm,mcc,sp\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    auc,acc,precesion,recall,f1,cm,mcc,sps = cross_valid('lb',**lgb_params)\n",
    "#     auc,acc,precesion,recall,f1,cm,mcc,sps = cross_valid('xb',**xgb_params)\n",
    "#     auc,acc,precesion,recall,f1,cm,mcc,sps = cross_valid('rf',**rf_params)\n",
    "#     auc,acc,precesion,recall,f1,cm,mcc,sps = cross_valid('et',**et_params)\n",
    "    print(f'''auc:{np.mean(auc):.4f}\\tacc:{np.mean(acc):.4f}\\tprecesion:{np.mean(precesion):.4f}\n",
    "        recall:{np.mean(recall):.4f}\\tf1:{np.mean(f1):.4f}\\tmcc:{np.mean(mcc):.4f}\\tsp:{np.mean(sps):.4f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a46b9dc-4861-4b61-bb39-23ddb4414afa",
   "metadata": {},
   "source": [
    "# Y-randomize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367277f5-810f-44ef-94d3-4f7b2c987d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def y_randomization(model_type):\n",
    "    assert type(model_type)==str,print('string type required')\n",
    "    aucs,accs,precesions,recalls,f1s,mccs,cms,sps = [],[],[],[],[],[],[],[]\n",
    "    for i in range(1,501):\n",
    "        print('*'*30,i,'*'*30)\n",
    "        df_label = data_drop(random_state=i)\n",
    "        if model_type=='lgb':\n",
    "            lgb_model,y_pred ,y_train_pred= model('lb',x_train,y_train,x_test,y_test,**lgb_params)\n",
    "            auc,acc,precesion,recall,f1,mcc,cm,sp = model_predict('lb',y_test,y_pred)\n",
    "            aucs.append(auc)\n",
    "            accs.append(acc)\n",
    "            precesions.append(precesion)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            mccs.append(mcc)\n",
    "            sps.append(sp)\n",
    "            cms.append(cm)\n",
    "        elif model_type=='xgb':\n",
    "            xgb_model,y_pred ,y_train_pred= model('xb',x_train,y_train,x_test,y_test,**xgb_params)\n",
    "            auc,acc,precesion,recall,f1,mcc,cm,sp = model_predict('xb',y_test,y_pred)\n",
    "            aucs.append(auc)\n",
    "            accs.append(acc)\n",
    "            precesions.append(precesion)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            mccs.append(mcc)\n",
    "            sps.append(sp)\n",
    "            cms.append(cm)\n",
    "        elif model_type=='rf':\n",
    "            rf_model,y_pred ,y_train_pred= model('rf',x_train,y_train,x_test,y_test,random_state=123123,**rf_params)\n",
    "            auc,acc,precesion,recall,f1,mcc,cm,sp = model_predict('rf',y_test,y_pred)\n",
    "            aucs.append(auc)\n",
    "            accs.append(acc)\n",
    "            precesions.append(precesion)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            mccs.append(mcc)\n",
    "            sps.append(sp)\n",
    "            cms.append(cm)\n",
    "        else:\n",
    "            et_model,y_pred ,y_train_pred= model('et',x_train,y_train,x_test,y_test,random_state=100,**et_params)\n",
    "            auc,acc,precesion,recall,f1,mcc,cm,sp = model_predict('et',y_test,y_pred)\n",
    "            aucs.append(auc)\n",
    "            accs.append(acc)\n",
    "            precesions.append(precesion)\n",
    "            recalls.append(recall)\n",
    "            f1s.append(f1)\n",
    "            mccs.append(mcc)\n",
    "            sps.append(sp)\n",
    "            cms.append(cm)\n",
    "    return aucs,accs,precesions,recalls,f1s,mccs,cms,sps\n",
    "aucs,accs,precesions,recalls,f1s,mccs,cms,sps = y_randomization('lb')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee7f9d8-cda6-4b49-97f1-3e43c869fcd8",
   "metadata": {},
   "source": [
    "# Predicting unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636d4dae-2c27-4000-85c6-69ab26146fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vivo_fp = pd.read_csv('../data/Fingerprint/vivo_all_drop_fp_2048_4.csv')\n",
    "data_vivo = pd.read_csv('../data/Raw_data/vivo_all_drop.csv')\n",
    "def unseen_predict():\n",
    "    all_index = []\n",
    "    xgbdata = xgb.DMatrix(vivo_fp)\n",
    "    lgb_predict = np.where(lgb_model.predict(vivo_fp,num_iteration=lgb_model.best_iteration)>=0.5,1,0)\n",
    "    xgb_predict = np.where(xgb_model.predict(xgbdata, iteration_range=(0, xgb_model.best_iteration+1))>=0.5,1,0)\n",
    "    rf_predict = np.where(rf_model.predict_proba(vivo_fp)[:,1]>=0.5,1,0)\n",
    "    et_predict = np.where(et_model.predict_proba(vivo_fp)[:,1]>=0.5,1,0)\n",
    "    for i,j in enumerate(lgb_predict):\n",
    "        if j==1:\n",
    "            all_index.append(i)\n",
    "    for i,j in enumerate(xgb_predict):\n",
    "        if j==1:\n",
    "            all_index.append(i)\n",
    "    for i,j in enumerate(rf_predict):\n",
    "        if j==1:\n",
    "            all_index.append(i)\n",
    "    for i,j in enumerate(et_predict):\n",
    "        if j==1:\n",
    "            all_index.append(i)\n",
    "    all_index = list(set(all_index))\n",
    "    return lgb_predict,xgb_predict,rf_predict ,et_predict,all_index\n",
    "lgb_predict,xgb_predict,rf_predict ,et_predict,all_index = unseen_predict()\n",
    "data_vivo_new = data_vivo.iloc[all_index]\n",
    "data_vivo_new.index = range(len(data_vivo_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f015ab-ae53-447e-96c6-8a6973527ef1",
   "metadata": {},
   "source": [
    "# Filter molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff19e638-0c6d-4c63-ae95-a25c06f1f71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = [Chem.MolFromSmiles(smi) for smi in data_vivo_new['smiles']]\n",
    "\n",
    "MW = []\n",
    "HA = []\n",
    "HB = []\n",
    "ROT = []\n",
    "PSA = []\n",
    "qeds = []\n",
    "\n",
    "for zinc, mol in zip(data_vivo_new['zinc_id'], mols):\n",
    "    \n",
    "    link = QED.properties(mol)\n",
    "    qed = QED.qed(mol)\n",
    "    MW.append([zinc, link.MW])\n",
    "    HA.append([zinc, link.HBA])\n",
    "    HB.append([zinc, link.HBD])\n",
    "    ROT.append([zinc, link.ROTB])\n",
    "    PSA.append([zinc, link.ALOGP])\n",
    "    qeds.append([zinc, qed])\n",
    "\n",
    "vivo_qed = pd.DataFrame(MW, columns=['zinc_id', 'MW'])\n",
    "vivo_qed['HBA'] = [zic[1] for zic in HA]\n",
    "vivo_qed['HBD'] = [zic[1] for zic in HB]\n",
    "vivo_qed['ROTB'] = [zic[1] for zic in ROT]\n",
    "vivo_qed['LOGP'] = [zic[1] for zic in PSA]\n",
    "vivo_qed['QED'] = [zic[1] for zic in qeds]\n",
    "vivo_qed['smiles'] = data_vivo_new['smiles']\n",
    "\n",
    "vivo_qed_new = vivo_qed[(vivo_qed[\"MW\"]<= 600) & (vivo_qed[\"HBA\"]<=10) & (vivo_qed[\"HBD\"]<=5) & (vivo_qed[\"ROTB\"]<=10) & (vivo_qed[\"LOGP\"]<=7) & (vivo_qed[\"LOGP\"]>= 0)]\n",
    "vivo_qed_new.index = range(len(vivo_qed_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8d8367-9be8-4203-8f57-0885ecf8a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "import os\n",
    "import os.path as op\n",
    " \n",
    "_fscores = None\n",
    " \n",
    " \n",
    "def readFragmentScores(name='fpscores'):\n",
    "    import gzip\n",
    "    global _fscores\n",
    "    if name == \"fpscores\":\n",
    "        name = op.join(os.getcwd(), name)\n",
    "    data = pickle.load(gzip.open('%s.pkl.gz' % name))\n",
    "    outDict = {}\n",
    "    for i in data:\n",
    "        for j in range(1, len(i)):\n",
    "            outDict[i[j]] = float(i[0])\n",
    "    _fscores = outDict\n",
    " \n",
    " \n",
    "def numBridgeheadsAndSpiro(mol, ri=None):\n",
    "    nSpiro = rdMolDescriptors.CalcNumSpiroAtoms(mol)\n",
    "    nBridgehead = rdMolDescriptors.CalcNumBridgeheadAtoms(mol)\n",
    "    return nBridgehead, nSpiro\n",
    " \n",
    " \n",
    "def calculateScore(m):\n",
    "    if _fscores is None:\n",
    "        readFragmentScores()\n",
    " \n",
    "    # fragment score\n",
    "    fp = rdMolDescriptors.GetMorganFingerprint(m,\n",
    "                                            2)  # <- 2 is the *radius* of the circular fingerprint\n",
    "    fps = fp.GetNonzeroElements()\n",
    "    score1 = 0.\n",
    "    nf = 0\n",
    "    for bitId, v in fps.items():\n",
    "        nf += v\n",
    "        sfp = bitId\n",
    "        score1 += _fscores.get(sfp, -4) * v\n",
    "    score1 /= nf\n",
    " \n",
    "    # features score\n",
    "    nAtoms = m.GetNumAtoms()\n",
    "    nChiralCenters = len(Chem.FindMolChiralCenters(m, includeUnassigned=True))\n",
    "    ri = m.GetRingInfo()\n",
    "    nBridgeheads, nSpiro = numBridgeheadsAndSpiro(m, ri)\n",
    "    nMacrocycles = 0\n",
    "    for x in ri.AtomRings():\n",
    "        if len(x) > 8:\n",
    "            nMacrocycles += 1\n",
    " \n",
    "    sizePenalty = nAtoms**1.005 - nAtoms\n",
    "    stereoPenalty = math.log10(nChiralCenters + 1)\n",
    "    spiroPenalty = math.log10(nSpiro + 1)\n",
    "    bridgePenalty = math.log10(nBridgeheads + 1)\n",
    "    macrocyclePenalty = 0.\n",
    "    if nMacrocycles > 0:\n",
    "        macrocyclePenalty = math.log10(2)\n",
    " \n",
    "    score2 = 0. - sizePenalty - stereoPenalty - spiroPenalty - bridgePenalty - macrocyclePenalty\n",
    "    score3 = 0.\n",
    "    if nAtoms > len(fps):\n",
    "        score3 = math.log(float(nAtoms) / len(fps)) * .5\n",
    " \n",
    "    sascore = score1 + score2 + score3\n",
    "    min = -4.0\n",
    "    max = 2.5\n",
    "    sascore = 11. - (sascore - min + 1) / (max - min) * 9.\n",
    "    # smooth the 10-end\n",
    "    if sascore > 8.:\n",
    "        sascore = 8. + math.log(sascore + 1. - 9.)\n",
    "    if sascore > 10.:\n",
    "        sascore = 10.0\n",
    "    elif sascore < 1.:\n",
    "        sascore = 1.0\n",
    " \n",
    "    return sascore\n",
    "def my_score(mols:list):\n",
    "    readFragmentScores(\"fpscores\")\n",
    "    smiles_s = []\n",
    "    for i,m in enumerate(mols):\n",
    "        s = calculateScore(m)\n",
    "        smiles = Chem.MolToSmiles(m)\n",
    "        smiles_s.append([i,smiles,s,vivo_qed_new.iloc[i,0]])\n",
    "    return smiles_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036aee8b-a15d-4e79-be6a-0f2683f87ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiles=my_score([Chem.MolFromSmiles(i) for i in vivo_qed_new['smiles']])\n",
    "filter_molecule = []\n",
    "for i in range(len(smiles)):\n",
    "    if smiles[i][2] < 4.5:\n",
    "        filter_molecule.append([smiles[i][1],smiles[i][2],smiles[i][3]])\n",
    "len(filter_molecule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
